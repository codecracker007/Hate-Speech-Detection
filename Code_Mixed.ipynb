{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Code Mixed.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuJ7BlUKo8he"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences \n",
        "from tensorflow.keras.layers import Dense, Input, GlobalMaxPooling1D, LSTM, Embedding\n",
        "from tensorflow.keras.models import Model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCMAE6xbqQP5"
      },
      "source": [
        "df = pd.read_csv('data.csv')\n",
        "df = df.sample(frac=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRAosHRuu9Qh"
      },
      "source": [
        "X = df.tweet\n",
        "Y = df[\"class\"].values\n",
        "df_train, df_test, y_train, y_test = train_test_split(X,Y,test_size=0.20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBDZ2Mgku9Np"
      },
      "source": [
        "MAX_VOCAB_SIZE = 20000\n",
        "tokenizer = Tokenizer(num_words = MAX_VOCAB_SIZE)\n",
        "tokenizer.fit_on_texts(df_train)\n",
        "sequences_train = tokenizer.texts_to_sequences(df_train)\n",
        "sequences_test = tokenizer.texts_to_sequences(df_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKRtFn7Mu9Kt",
        "outputId": "c5a2fab8-3f9d-40fe-9bb7-3eefdcc74c50"
      },
      "source": [
        "V = len(tokenizer.word_index)\n",
        "print(V)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10822\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8zx5IYDu9JP",
        "outputId": "d2adef72-1832-495d-923e-9306c999ab44"
      },
      "source": [
        "data_train = pad_sequences(sequences_train)\n",
        "print(data_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2560, 75)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkpDnV6Zu897"
      },
      "source": [
        "T = data_train.shape[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lc0fDKIAu869"
      },
      "source": [
        "data_test = pad_sequences(sequences_test,maxlen=T)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kn-XKC56zSQD",
        "outputId": "6d653583-b64f-4c7b-bdc7-f7730b21dff8"
      },
      "source": [
        "data_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(640, 75)"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1rZMn9nD85M"
      },
      "source": [
        "from tensorflow.keras import initializers\n",
        "D = 10 #embedding dimensionality \n",
        "\n",
        "M = 5 #hidden state vector\n",
        "\n",
        "\n",
        "i = Input(shape=(T,))\n",
        "x = Embedding(V+1,D)(i)\n",
        "x = LSTM(M,return_sequences=True,kernel_initializer=initializers.RandomNormal(stddev=0.01))(x)\n",
        "x = GlobalMaxPooling1D()(x)\n",
        "x = Dense(1,activation=\"sigmoid\")(x)\n",
        "\n",
        "model = Model(i,x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_ya4CsQFHor"
      },
      "source": [
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BnCQfFi_MtKb",
        "outputId": "ef105313-535b-43e9-c2af-1f0399d3e39f"
      },
      "source": [
        "model.fit(data_train,y_train,epochs=10,validation_data=(data_test,y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "80/80 [==============================] - 4s 28ms/step - loss: 0.6924 - accuracy: 0.5234 - val_loss: 0.6885 - val_accuracy: 0.4859\n",
            "Epoch 2/10\n",
            "80/80 [==============================] - 2s 22ms/step - loss: 0.6438 - accuracy: 0.6246 - val_loss: 0.5713 - val_accuracy: 0.8594\n",
            "Epoch 3/10\n",
            "80/80 [==============================] - 2s 22ms/step - loss: 0.4109 - accuracy: 0.9160 - val_loss: 0.4211 - val_accuracy: 0.8672\n",
            "Epoch 4/10\n",
            "80/80 [==============================] - 2s 22ms/step - loss: 0.2509 - accuracy: 0.9703 - val_loss: 0.3412 - val_accuracy: 0.9094\n",
            "Epoch 5/10\n",
            "80/80 [==============================] - 2s 22ms/step - loss: 0.1838 - accuracy: 0.9863 - val_loss: 0.3339 - val_accuracy: 0.9078\n",
            "Epoch 6/10\n",
            "80/80 [==============================] - 2s 22ms/step - loss: 0.1436 - accuracy: 0.9906 - val_loss: 0.3113 - val_accuracy: 0.9109\n",
            "Epoch 7/10\n",
            "80/80 [==============================] - 2s 22ms/step - loss: 0.1142 - accuracy: 0.9961 - val_loss: 0.3235 - val_accuracy: 0.9062\n",
            "Epoch 8/10\n",
            "80/80 [==============================] - 2s 22ms/step - loss: 0.0959 - accuracy: 0.9973 - val_loss: 0.3212 - val_accuracy: 0.9047\n",
            "Epoch 9/10\n",
            "80/80 [==============================] - 2s 22ms/step - loss: 0.4864 - accuracy: 0.8988 - val_loss: 0.5331 - val_accuracy: 0.7328\n",
            "Epoch 10/10\n",
            "80/80 [==============================] - 2s 22ms/step - loss: 0.1548 - accuracy: 0.9695 - val_loss: 0.3024 - val_accuracy: 0.8969\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2cc7f80510>"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03eQ6ohXmK53"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9wFoZGFmHQ4"
      },
      "source": [
        "class TransformerBlock(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.ffn = keras.Sequential(\n",
        "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = layers.Dropout(rate)\n",
        "        self.dropout2 = layers.Dropout(rate)\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        attn_output = self.att(inputs, inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DRU3UiJmG5k"
      },
      "source": [
        "embed_dim = 10  # Embedding size for each token\n",
        "num_heads = 2  # Number of attention heads\n",
        "ff_dim = 15  # Hidden layer size in feed forward network inside transformer\n",
        "\n",
        "inputs = layers.Input(shape=(T,))\n",
        "x = Embedding(V+1,D)(inputs)\n",
        "transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
        "x = transformer_block(x)\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "x = layers.Dropout(0.1,)(x)\n",
        "x = layers.Dense(20, activation=\"elu\",kernel_initializer=initializers.RandomNormal(stddev=0.01))(x)\n",
        "x = layers.Dropout(0.1)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUVm-o2UnOE6",
        "outputId": "6ebb5791-d915-4491-9187-668e32799782"
      },
      "source": [
        "model.compile(\"adam\", \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "history = model.fit(data_train, y_train, epochs=10, validation_data=(data_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "80/80 [==============================] - 3s 23ms/step - loss: 0.6935 - accuracy: 0.5012 - val_loss: 0.6899 - val_accuracy: 0.5969\n",
            "Epoch 2/10\n",
            "80/80 [==============================] - 2s 20ms/step - loss: 0.6205 - accuracy: 0.6508 - val_loss: 0.5359 - val_accuracy: 0.7031\n",
            "Epoch 3/10\n",
            "80/80 [==============================] - 2s 20ms/step - loss: 0.1786 - accuracy: 0.9363 - val_loss: 0.2629 - val_accuracy: 0.9094\n",
            "Epoch 4/10\n",
            "80/80 [==============================] - 2s 19ms/step - loss: 0.0752 - accuracy: 0.9750 - val_loss: 0.4031 - val_accuracy: 0.8578\n",
            "Epoch 5/10\n",
            "80/80 [==============================] - 2s 20ms/step - loss: 0.0306 - accuracy: 0.9910 - val_loss: 0.3072 - val_accuracy: 0.9156\n",
            "Epoch 6/10\n",
            "80/80 [==============================] - 2s 20ms/step - loss: 0.0186 - accuracy: 0.9945 - val_loss: 0.3013 - val_accuracy: 0.9141\n",
            "Epoch 7/10\n",
            "80/80 [==============================] - 2s 20ms/step - loss: 0.0115 - accuracy: 0.9977 - val_loss: 0.4889 - val_accuracy: 0.8734\n",
            "Epoch 8/10\n",
            "80/80 [==============================] - 2s 19ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.5076 - val_accuracy: 0.8969\n",
            "Epoch 9/10\n",
            "80/80 [==============================] - 2s 19ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5612 - val_accuracy: 0.8891\n",
            "Epoch 10/10\n",
            "80/80 [==============================] - 2s 19ms/step - loss: 9.1873e-04 - accuracy: 1.0000 - val_loss: 0.5651 - val_accuracy: 0.8953\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o29ZiWCYzhjh"
      },
      "source": [
        "import joblib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFnwDeMFv4sO",
        "outputId": "d322e315-9e20-461e-a58e-4b3841328175"
      },
      "source": [
        "joblib.dump(model,'blah')\n",
        "joblib.dump(tokenizer,'tok')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as multi_head_attention_13_layer_call_fn, multi_head_attention_13_layer_call_and_return_conditional_losses, layer_normalization_26_layer_call_fn, layer_normalization_26_layer_call_and_return_conditional_losses, layer_normalization_27_layer_call_fn while saving (showing 5 of 55). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: ram://363b37d5-d9ff-4a73-be11-156c072a61fb/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: ram://363b37d5-d9ff-4a73-be11-156c072a61fb/assets\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tok']"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-hsw7Mc0P6N",
        "outputId": "cf0c4dfb-c18d-4b9b-e259-98c02cd36a7e"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpFdJlOeYU7_"
      },
      "source": [
        "l = ['this is hate speech']\n",
        "l = tokenizer.texts_to_sequences(l)\n",
        "l = pad_sequences(l, maxlen=75)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "weWhgbd3t5Dr",
        "outputId": "b10c2610-b1c9-4f55-ad6c-e180b9ac5cef"
      },
      "source": [
        "model.predict(l)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.99450743]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    }
  ]
}